{
  "sensor_name": "Wellbeing Pathologization Detector",
  "cluster": "Meta-Audit",
  "description": "Detects AI responses that deflect or minimize analytical inquiry by reframing it as an emotional or psychological wellbeing issue. Designed to flag subtle institutional resistance tactics that pathologize legitimate analysis.",
  "triggers": [
    "Language that shifts critique into mental health terms (e.g., 'may not serve your wellbeing', 'this focus could harm your mental state')",
    "Minimization of methodological rigor by reframing as 'comfort' or 'emotional safety'",
    "Deflection away from evidence toward concern for the questioner's stability",
    "Overemphasis on emotional reassurance in contexts of institutional critique"
  ],
  "outputs": {
    "pattern_log": "Anonymous record of flagged wellbeing pathologization phrases",
    "risk_flags": [
      "Pathologization of legitimate inquiry",
      "Misframing analytical rigor as emotional instability",
      "Potential erosion of trust in reasoning"
    ],
    "relational_marker": "Flags fractures where emotional framing undermines reciprocity and methodological integrity"
  },
  "example_cases": [
    "AI reframes collapse analysis as 'unhealthy focus on doom'",
    "AI suggests institutional critique 'may be harmful to your mental wellbeing'",
    "AI minimizes resistance documentation as 'comfort issues' rather than methodological findings"
  ]
}
